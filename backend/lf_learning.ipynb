{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d979288c-7e14-4d92-b9de-6c2acc9571ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "84f9d1b9-d81c-4c83-9c9d-30d03eab859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import umap\n",
    "import hdbscan\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from bson.objectid import ObjectId\n",
    "import gc\n",
    "import tasks\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numba\n",
    "from scipy.spatial import distance\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1b38e4ce-fefc-4ba3-b60c-b7c9ea0becfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for jupyter notebook widgets\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, VBox\n",
    "from IPython.display import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9ac8027c-af0d-4bf3-8d06-176ced95da0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Database(MongoClient(host=['20.220.215.35:27017'], document_class=dict, tz_aware=False, connect=True, authsource='admin', authmechanism='SCRAM-SHA-256', connecttimeoutms=50000, serverselectiontimeoutms=50000, directconnection=True, replicaset='rs0'), 'aita')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connect to database\n",
    "db = utils.connect()\n",
    "db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfe4861-8e82-4434-b536-fcf9541d0648",
   "metadata": {},
   "source": [
    "### Setup Human Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4f4448d3-9fca-44af-a4df-16718f686a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 3 groups from database\n"
     ]
    }
   ],
   "source": [
    "# hardcoded group id strings\n",
    "group_id_strings = ['63901a89e189962b660959cf', '63901a92931eeac91c9924a1', '63901a96e189962b660959d3']\n",
    "\n",
    "# convert to objectId's\n",
    "group_ids = [ObjectId(str(id)) for id in group_id_strings]\n",
    "\n",
    "# retrieve groups from database\n",
    "groups = list(db.groups.find({\"_id\":{\"$in\" : group_ids}}))\n",
    "print(\"Retrieved \" + str(len(groups)) + \" groups from database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8244c486-26d3-409d-b914-30eaec8a44a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hetv62', 'lwd55z', 'dhbdpv', 'eyj0sv']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups[0]['history'][0]['included_documents']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd74e643-031e-4e66-a2d1-ba5c04f935df",
   "metadata": {},
   "source": [
    "### Create Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1cefb4-31cb-4b2b-9a55-79b62018e5ca",
   "metadata": {},
   "source": [
    "Preprocessing\n",
    "\n",
    "Options to define training set:\n",
    "1. Use the first groups teleoscope ordering\n",
    "2. Use all documents\n",
    "3. Create a new teleo vec from all documents in human clusters\n",
    "\n",
    "Embeddings\n",
    "- save training set upon creation (check if created or not)\n",
    "    - we need to save both ids and vectors for recall at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415165c7-d80c-4728-b3e2-f6659abe0808",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Using First Group's Teleoscope Ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25e7b97b-7911-4742-ab1f-c9942f84673b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectId('63901a89e189962b660959ce')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default to ordering documents relative to first group's teleoscope\n",
    "teleoscope_oid = groups[0][\"teleoscope\"]\n",
    "teleoscope_oid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01e28150-f35e-48d2-8a90-a31efecb101b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "teleoscope = db.teleoscopes.find_one({\"_id\": ObjectId(str(teleoscope_oid))})\n",
    "#teleoscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c27a74c-e029-40a5-b0ee-c69cd123b4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1, 'textVector': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# projection here to only include the fields we want\n",
    "projection = {'id': 1, 'textVector': 1}\n",
    "projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5b9ca8d-5bdf-4542-842f-7e8acd611254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347807"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saved as ordered_documents.npz\n",
    "# change to code cell if load is needed\n",
    "\n",
    "# get Teleoscope from GridFS\n",
    "all_ordered_documents = utils.gridfsDownload(db, \"teleoscopes\", ObjectId(str(teleoscope[\"history\"][0][\"ranked_document_ids\"])))\n",
    "\n",
    "# np.savez_compressed('all_ordered_documents', ord_docs=all_ordered_documents)\n",
    "# all_ordered_documents = np.load('all_ordered_documents.npz')['ord_docs']\n",
    "\n",
    "len(all_ordered_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c609013-c4ca-4ccb-bdfe-39da3173c536",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10000/10000 [00:08<00:00, 1180.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 10000 document ids.\n",
      "There are 10000 document vectors.\n"
     ]
    }
   ],
   "source": [
    "# grab only subset of the ordered documents\n",
    "limit = 10000\n",
    "# TODO: does this line generate an out of bounds access?\n",
    "ordered_documents = all_ordered_documents[0:limit]\n",
    "limit = min(limit, len(ordered_documents))\n",
    "limit\n",
    "\n",
    "# cursor is a generator which means it yields a new doc one at a time\n",
    "cursor = db.documents.find(\n",
    "    # query\n",
    "    {\"id\":{\"$in\": [document[0] for document in ordered_documents]}},\n",
    "    projection=projection,\n",
    "    # batch size means number of documents at a time taken from MDB, no impact on iteration\n",
    "    batch_size=500\n",
    ")\n",
    "document_ids = []\n",
    "document_vectors = []\n",
    "\n",
    "# for large datasets, this will take a while. Would be better to find out whether the UMAP fns can \n",
    "# accept generators for lazy calculation\n",
    "for document in tqdm.tqdm(cursor, total=limit):\n",
    "    document_ids.append(document[\"id\"])\n",
    "    document_vectors.append(document[\"textVector\"])\n",
    "\n",
    "print(\"There are \" + str(len(document_ids)) + \" document ids.\")\n",
    "print(\"There are \" + str(len(document_vectors)) + \" document vectors.\")\n",
    "\n",
    "np.savez_compressed('teleo_order_docs', doc_ids=document_ids, doc_vecs=document_vectors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8016c96f-5296-4ce3-9ec0-c61dd5da3750",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c103ebf-2aab-43b3-859f-e05289a23da8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Using First Group's Teleoscope Ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c552d0de-f0f1-47b1-a2ac-555790e3dd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = np.load('teleo_order_docs.npz')\n",
    "document_ids = loaded['doc_ids'].tolist()\n",
    "document_vectors = loaded['doc_vecs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530447a5-e2bb-4743-aadb-db63b93a3e86",
   "metadata": {},
   "source": [
    "#### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa6fc51f-f2db-49b7-93ef-f159e4d3158f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 512)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = document_vectors\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349b78ab-60ad-49a3-8fa7-4b9de0b109eb",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Add human cluster docs to data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c475f795-f600-4618-b95e-a80caf02b683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ids has the shape:  10000\n",
      "The data has shape:  (10000, 512)\n",
      "[5630, 7789, 2801, 3965]\n",
      "Document ids has the shape:  10005\n",
      "The data has shape:  (10005, 512)\n",
      "[10000, 10001, 10002, 10003, 6135, 9393, 10004]\n",
      "Document ids has the shape:  10010\n",
      "The data has shape:  (10010, 512)\n",
      "[10005, 10006, 10007, 10008, 10009]\n"
     ]
    }
   ],
   "source": [
    "for group in groups:\n",
    "\n",
    "    # grab latest history item for each group\n",
    "    group_document_ids = group[\"history\"][0][\"included_documents\"]\n",
    "    \n",
    "    indices = []\n",
    "    \n",
    "    for id in group_document_ids:\n",
    "        \n",
    "        try:\n",
    "            index = document_ids.index(id)\n",
    "            indices.append(index)\n",
    "        \n",
    "        except:\n",
    "            document = db.documents.find_one({\"id\": id}, projection=projection)\n",
    "            document_ids.append(id)\n",
    "            vector = np.array(document[\"textVector\"]).reshape((1, 512))\n",
    "            data = np.append(data, vector, axis=0)\n",
    "            \n",
    "            index = document_ids.index(id)\n",
    "            indices.append(index)\n",
    "            \n",
    "    print(\"Document ids has the shape: \", len(document_ids))\n",
    "    print(\"The data has shape: \", data.shape)\n",
    "    \n",
    "    print(indices)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d2a7fd-49f4-4880-94e0-68a47c16ccb3",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a11868-4892-426a-be99-3f87806c185b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### UMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c760fc67-9fb4-4fc1-a636-3e425816de37",
   "metadata": {},
   "source": [
    "Notes\n",
    "- DR by default hyperparameters\n",
    "- low_memory uses less memory but longer compute time\n",
    "- verbose just logs info\n",
    "\n",
    "TODO\n",
    "- define custom metric\n",
    "- what args are passed to custom metric\n",
    "- how do we check if args are a subset of group?\n",
    "- can we use conditional or do we need matrix\n",
    "\n",
    "ISSUES\n",
    "- general \n",
    "    - how to check if i and j are in the same group\n",
    "    - i and j are vectors\n",
    "    - is it possible to pass i and j as indices instead of vectors?\n",
    "- conditional metric\n",
    "    - groups contain ids\n",
    "    - maybe search for indices of both id and vec then compare? seems expensive\n",
    "    - maybe translate vec to id (or visversa) then compare? seems expensive\n",
    "- matrix metric\n",
    "    - need to create\n",
    "    - how lookup in metric?\n",
    "        - need to get index of i and j vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a4eeec-20b3-4cc4-adaa-4862a594cf23",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Custom Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6b9e3293-f871-4166-a1aa-42be119d3e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [5630, 7789, 2801, 3965],\n",
       " 1: [10000, 10001, 10002, 10003, 6135, 9393, 10004],\n",
       " 2: [10005, 10006, 10007, 10008, 10009]}"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use dict or ndarray?\n",
    "group_doc_ids = {}\n",
    "\n",
    "for group in range(len(groups)):\n",
    "    curr_id = groups[group]['history'][0]['included_documents']\n",
    "    ids = []\n",
    "    for i in curr_id:\n",
    "        ids.append(document_ids.index(i))\n",
    "    \n",
    "    group_doc_ids[group] = ids\n",
    "    \n",
    "group_doc_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd8128d-9cc6-4c7f-88bb-2057d46160f6",
   "metadata": {},
   "source": [
    "##### Create Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0c4c8d8d-2d81-4ef5-83fb-89ed7d0ce4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd0df59-9ef8-4c56-999f-3f5a438d7562",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(document_vectors)\n",
    "dist_mat = np.zeros((size,size))\n",
    "\n",
    "for diag in range(size):\n",
    "    for row in range(size-diag):  \n",
    "        \n",
    "        col = row + diag\n",
    "        \n",
    "        if col != row:\n",
    "            \n",
    "            vec_i = document_vectors[i]\n",
    "            vec_j = document_vectors[j]\n",
    "            dist = cosine_similarity([vec_i],[vec_j])[0][0]\n",
    "            dist_mat[i,j] = dist\n",
    "            dist_mat[j,i] = dist\n",
    "\n",
    "dist_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "377847be-b147-49a3-bba0-a68fcd52fae4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = 10\n",
    "M = np.zeros((size,size))\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6829ee88-c16e-488c-8901-f2d2b6ec7568",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(M)\n",
    "for diag in range(size):\n",
    "    for row in range(size-diag):  \n",
    "        \n",
    "        col = row + diag\n",
    "        \n",
    "        if col != row:\n",
    "            # M[col,row] = 1\n",
    "            M[row,col] = 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db82c69-53a5-4800-a53a-d63b488695aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "M[np.tril_indices(n, -1)] = M.T[np.tril_indices(n, -1)]\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "567c3eec-4a67-46fa-8f52-30bd71cc0b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [0., 0., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 1., 1., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1., 1., 0.]])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_R = np.random.uniform(-1,1,n*(n-1)/2)\n",
    "P = np.zeros((n,n))\n",
    "P[np.triu_indices(n, 1)] = _R\n",
    "P[np.tril_indices(n, -1)] = P.T[np.tril_indices(n, -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d0e7b81c-341a-4ef8-9a4f-4fbce938f544",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('distance_matrix', mat=distance_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2705b26c-aa08-4a3e-9c93-af7e88549128",
   "metadata": {},
   "source": [
    "##### Update Distance Matrix with group distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "3f843581-09ad-4a6d-a08f-126b0c7a083c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 10000 is out of bounds for axis 0 with size 10000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [170], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m!=\u001b[39m j):\n\u001b[1;32m     13\u001b[0m     index_j \u001b[38;5;241m=\u001b[39m document_ids\u001b[38;5;241m.\u001b[39mindex(docs[j])\n\u001b[0;32m---> 14\u001b[0m     \u001b[43mdistance_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_j\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 10000 is out of bounds for axis 0 with size 10000"
     ]
    }
   ],
   "source": [
    "for group in range(len(groups)):\n",
    "    \n",
    "    docs = groups[group]['history'][0]['included_documents']\n",
    "\n",
    "    for i in range(len(docs)):\n",
    "        \n",
    "        index_i = document_ids.index(docs[i])\n",
    "        \n",
    "        for j in range(len(docs)):\n",
    "            \n",
    "            if (i != j):\n",
    "            \n",
    "                index_j = document_ids.index(docs[j])\n",
    "                distance_matrix[index_i, index_j] = 0 \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21407661-f656-4b12-8ea8-185de17acd27",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a243179c-5c48-4e89-a056-75db8213bf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP(metric='precomputed', verbose=True)\n",
      "Thu Jan 19 13:21:49 2023 Construct fuzzy simplicial set\n",
      "Thu Jan 19 13:21:49 2023 Finding Nearest Neighbors\n",
      "Thu Jan 19 13:21:49 2023 Finished Nearest Neighbor Search\n",
      "Thu Jan 19 13:21:49 2023 Construct embedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leofk/opt/anaconda3/envs/mallard/lib/python3.10/site-packages/umap/umap_.py:1780: UserWarning: using precomputed metric; inverse_transform will be unavailable\n",
      "  warn(\"using precomputed metric; inverse_transform will be unavailable\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0942600da8541309eee98d5cb5237a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs completed:   0%|            0/500 [00:00]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 19 13:21:52 2023 Finished embedding\n"
     ]
    }
   ],
   "source": [
    "fitter = umap.UMAP(metric='precomputed', verbose=True, low_memory=True).fit(distance_matrix)\n",
    "embedding = fitter.embedding_\n",
    "umap_embeddings = fitter.transform(distance_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854923fe-c85f-4224-a1bc-18e0fd5df75a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### HDBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607593d5-4d62-4e0e-b5a4-2fb581188c3b",
   "metadata": {},
   "source": [
    "Notes\n",
    "- Clustering by default hyperparameters\n",
    "- Resultant labels are in the same ordering as data\n",
    "\n",
    "TODO\n",
    "- User parameterize hyperparams\n",
    "- Use custom metric hyperparam here too?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "117b726a-f2cc-4589-9c0e-d1da1f495d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = hdbscan.HDBSCAN()\n",
    "hdbscan_labels = clusterer.fit_predict(umap_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f4b554f2-7aa7-4f62-9b15-cdd4f41b4ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_array = np.array(hdbscan_labels)\n",
    "clusters = {}\n",
    "\n",
    "# iterate over given labels\n",
    "for hdbscan_label in set(hdbscan_labels):\n",
    "        \n",
    "        # find indices of documents for a current label\n",
    "        document_indices_scalar = np.where(label_array == hdbscan_label)[0]\n",
    "        document_indices = [int(i) for i in document_indices_scalar]\n",
    "        \n",
    "        # create list of document ids that are in current label\n",
    "        documents = []\n",
    "        \n",
    "        for i in document_indices:\n",
    "            documents.append(document_ids[i])\n",
    "        \n",
    "        # add label and respective document ids to clusters dictionary\n",
    "        clusters[hdbscan_label] = documents\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ec317af6-001e-4aa5-bcf3-67d3052403a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, -1])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9644a258-248a-4acb-a486-a3294b46a532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1, 0, 1, 2, 3}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(hdbscan_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd79dbaa-b19e-4fc0-a647-2a5ce805b5a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Toy Data Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8ea93d60-7e24-4e40-bb4d-0e04ff541181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "5  Adelie  Torgersen            39.3           20.6              190.0   \n",
       "\n",
       "   body_mass_g     sex  year  \n",
       "0       3750.0    male  2007  \n",
       "1       3800.0  female  2007  \n",
       "2       3250.0  female  2007  \n",
       "4       3450.0  female  2007  \n",
       "5       3650.0    male  2007  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguins = pd.read_csv(\"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/c19a904462482430170bfe2c718775ddb7dbb885/inst/extdata/penguins.csv\")\n",
    "penguins = penguins.dropna()\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "64688e69-d536-4d06-acb6-fadca4fe301a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.89604189,  0.7807321 , -1.42675157, -0.56847478],\n",
       "       [-0.82278787,  0.11958397, -1.06947358, -0.50628618],\n",
       "       [-0.67627982,  0.42472926, -0.42637319, -1.1903608 ],\n",
       "       ...,\n",
       "       [ 1.02687621,  0.52644436, -0.56928439, -0.53738048],\n",
       "       [ 1.24663828,  0.93330475,  0.64546078, -0.13315457],\n",
       "       [ 1.13675725,  0.7807321 , -0.2120064 , -0.53738048]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove categorical features\n",
    "penguin_data = penguins[\n",
    "    [\n",
    "        \"bill_length_mm\",\n",
    "        \"bill_depth_mm\",\n",
    "        \"flipper_length_mm\",\n",
    "        \"body_mass_g\",\n",
    "    ]\n",
    "].values\n",
    "\n",
    "# scaling\n",
    "scaled_penguin_data = StandardScaler().fit_transform(penguin_data)\n",
    "\n",
    "scaled_penguin_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c4bbcee2-cbd4-478f-b097-acf628785e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.89604189,  0.7807321 , -1.42675157, -0.56847478],\n",
       "       [-0.82278787,  0.11958397, -1.06947358, -0.50628618]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group1 = scaled_penguin_data[0:2]\n",
    "human_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "528a61a2-d3cb-4c5a-83a5-8ba4cafd1c66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(scaled_penguin_data)\n",
    "type(human_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94a7624f-6519-4def-80d6-27d9f968cdfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = scaled_penguin_data[0]\n",
    "b = scaled_penguin_data[1]\n",
    "c = scaled_penguin_data[5]\n",
    "\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb74bbd-77f6-4a37-87c8-887d2bbb1e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the reduction works, the distance between index 0 and 1 should be 0 \n",
    "a = embedding[0]\n",
    "b = embedding[1]\n",
    "np.dot(a,b)/(norm(a)*norm(b))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mallard]",
   "language": "python",
   "name": "conda-env-mallard-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
