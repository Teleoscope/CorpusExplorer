# Methodologies
We originally built Teleoscope in an academic context targeting qualitative researchers. 
We have always had the needs of academics front and center. During our interviews and focus groups 
(which you can read about in our [paper](/academics/citations)), our participants told us how important
it was that using Teleoscope in a qualitative study could be explained to colleagues and reviewers. 

This section addresses our understanding of where Teleoscope fits in the qualitative research world,
but you might also find it useful to look at our [examples](/resources/examples), [lessons](/resources/lessons),
and [How-to](/resources/tutorials) sections to get more insight.

### Topic Models
Teleoscope fits under the umbrella of [topic modelling](https://en.wikipedia.org/wiki/Topic_model).
We use large language models [LLMs](https://en.wikipedia.org/wiki/Large_language_model) to provide
embeddings for your documents, and then use a variety of techniques to help you find and group documents
that are closest to your idea of what a good topic is.

### Your own interpretation
Teleoscope attempts to support computer-assisted qualitative research by putting the values of 
qualitative reseachers front-and-center. We wanted to reflect the process of arranging data by hand 
in the Teleoscope workspace. We also wanted to give qualitative researchers the feeling of really
digging into their data, even though they're searching through thousands or millions of documents.

Although Teleoscope uses LLMs, you are imposing your own interpretive perspective on the models by 
asking it to rank and group documents according to what you think is similar. Ideally, it is picking
up on your personal sense of thematic similarity.

### Managing personal bias through Provenance
Of course, we don't want to insert our own bias into our interpretations. It's a tough process to balance
the helpful intuitions we have as qualitative researchers with keeping a rigorous academic lens. 

That's why we built Teleosope with provenance as the foremost design metaphor. We wanted people to be 
able to continually re-trace their own steps, show their thought process to their colleagues, and amend 
it when needed. Below, we'll talk about our ideas of crystalization as it related to information power
and saturation.

### Overview of the Teleoscope Method

![Overview](/docs/teleoscope-overview-web.png)
(1) Start by performing a standard **keyword search** to explore documents;
(2) Drag **documents** onto the workspace;
(3) **Group** documents for organization;
(4) **Ranks** can use documents, notes or groups as control inputs;
(5) **Projections** create clusters using groups as control inputs;
(6) **Notes** can contain arbitrary text which is also vectorized and can be used as a control input to a Teleoscope;
(7) Read documents on the **sidebar** as well as edit your saved items, bookmarks, and settings. Keyboard navigation through document lists and bookmarking are included for quick exploration and group creation.

You can see how Teleoscope works by mixing the semantics of your control input examples.
Above, we have the concept of **fish** mixed with the concept of **vegetarianism**.
In the Teleoscope output, you can see that it has found documents that have to do with **pescatarianism**,
which is a dietary choice that is [like vegetarianism but you can also eat fish](https://en.wikipedia.org/wiki/Pescetarianism).
Nowhere in the text does it mention vegetarianism, yet it is highly ranked in the Teleoscope output.

### Document representation

Document similarity is basically a measure of how many words, phrases,
and sentences overlap between two documents.
For example, a [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model)
model might use the following process to produce a similarity score:

```
sentence_1 = "The dog walked to the park."
sentence_2 = "The dog chewed on a bone."
sentence_3 = "The dog napped in the park."
```

Getting rid of common words and word endings ([stemming](https://en.wikipedia.org/wiki/Stemming)),
the sentences would be turned into:

```
sentence_1 = "dog walk park"
sentence_2 = "dog chew bone"
sentence_3 = "dog nap park"
```

If we count the overlapping words, `sentence 1` and `sentence 3` are the most similar.
That should make intuitive sense: they both have "dog" and "park" in them. If we wanted
to use a vector representation to check similarity, we would create a vector where each
entry mapped to a single word. We will put a `1` in the vector if the word exists in the
sentence, and a `0` otherwise.

```
vector     = < dog walk park chew bone nap >
sentence_1 = <   1    1    1    0    0   0 >
sentence_2 = <   1    0    0    1    1   0 >
sentence_3 = <   1    0    1    0    0   1 >
```

This simple example is only to build some intuition for how a document can be represented by a vector.
We might want a model that "knows" that "cat" and "dog" are conceptually similar words.
In Teleoscope, we use a pre-built model called the
[Universal Sentence Encoder](https://www.tensorflow.org/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder)
which allows for more complex semantic similarity to be captured.
The USE model is good for capturing categorical similarities because it was trained on huge amounts of data.

There is a core design trade-off between using a pre-built model vs. building a model off of
the dataset that you're interested in studying. If you build your own model,
you will create similarity scores based on how often words show up together in your own dataset.
However, for words that most people would consider to be similar, you might not have enough data
to create good similarity scores. For example, we might have a dataset where "dog" and "cat"
do not appear very often near each other, or along with other conceptually similar words like "pet" or "fur".

By starting with a model that has been trained on large amounts of data,
we can capture semantics that a smaller model may not be able to.
However, then we have the problem of determining similarities that might be present in our dataset,
or in our minds, which may not be captured by the USE model.
However, Teleoscope is model-agnostic. If you wanted to create a version of Teleoscope
with a different model, it would be quite easy to do.

### The Teleoscope Rank

Teleoscope ranks documents by similarity using different LLMs.
When multiple documents are input as `controls`, the Teleoscope will average the
document vectors to give you a "mix" of the different vectors. In this way, a
Teleoscope search is a **search by example**. You can connect many documents to
tune the Teleoscope rank to follow conceptual similarities that you imagine.
You can also vectorize your own sentences by creating a **note** and add it into the mix.

In this way, you are building up a **visual trace** of a concept that you're exploring.
You can capture your own thought process by seeing which documents are feeding into the
Teleoscope, and what you had to do to come up with the machine representation you were interested in.

### Grouping and Projections

**Grouping** means that you've decided that certain documents are **thematically similar**
whether or not the machine has. Of course, this can just be an organizational tool,
but you can also use groups as inputs to Ranks and **Projections**.
This is where the power of the system can really be seen.

A **Projection** produces groups of documents that the machine has clustered together
as similar based on the groups you use as control inputs. It is called a projection
because it performs [dimensionality reduction](https://en.wikipedia.org/wiki/Dimensionality_reduction)
on the document vectors. Think "projection" like "projecting your shadow onto a wall."
It's taking something higher-dimensional and creating a lower-dimensional representation of it.
Teleoscope uses the [UMAP](https://umap-learn.readthedocs.io/en/latest/) library to perform our
projections and [HDBSCAN](https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html)
to perform our clustering.

The practical upshot is that our system will attempt to cluster the document source based on
the groups you provide. You can think of it like pruning a large, general language model
like USE for your specific way of thinking about your document set.
