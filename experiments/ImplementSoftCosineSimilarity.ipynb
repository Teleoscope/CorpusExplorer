{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBJECTIVE**\n",
    "- Understand what soft cosine similarity actually computes by implementing it from scratch\n",
    "- Use a simple example to compare difference in cosine similarity vs soft cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Soft Cosine Similarity**\n",
    "\n",
    "![title](images/scs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softCosineSimilarity(a: np.array, b: np.array, S: np.array) -> float:\n",
    "    \"\"\"\n",
    "    Soft Cosine Similarity (SCS) algorithm implemented via for loops for better understanding.\n",
    "    \n",
    "    Computes SCS between bag of words term frequency vectors a & b. Uses word-similarity matrix S\n",
    "    of shape NxN where N is number of unique words in corpus including a & b.\n",
    "\n",
    "    Parameters:\n",
    "    a (np.array): bag of words term frequency vector of sentence a\n",
    "    b (np.array): bag of words term frequency vector of sentence b\n",
    "    S (np.array): word similarity matrix\n",
    "\n",
    "    Returns:\n",
    "    float: soft cosine similarity between a & b.\n",
    "   \"\"\"\n",
    "    numerator = 0    \n",
    "    denominator_a = 0\n",
    "    denominator_b = 0\n",
    "    \n",
    "    # calculate numerator\n",
    "    for i in range(len(a)):\n",
    "        for j in range(len(a)):\n",
    "            numerator += (S[i][j])*a[i]*b[j]\n",
    "            denominator_a += (S[i][j])*a[i]*a[j]\n",
    "            denominator_b += (S[i][j])*b[i]*b[j]\n",
    "    \n",
    "    # calculate denominator a\n",
    "    denominator_a = np.sqrt(denominator_a)\n",
    "    # calculate denominator b\n",
    "    denominator_b = np.sqrt(denominator_b)\n",
    "    # calculate denominator\n",
    "    denominator = denominator_a*denominator_b\n",
    "    return round(numerator/denominator,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Soft Cosine Similarity (Matrix Form)**\n",
    "\n",
    "![title](images/scs_matrix.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softCosineSimilarityFast(a: np.array, b: np.array, S: np.array) -> float:\n",
    "    \"\"\"\n",
    "    Soft Cosine Similarity (SCS) algorithm implemented via matrix multiplication.\n",
    "    \n",
    "    Computes SCS between bag of words term frequency vectors a & b. Uses word-similarity matrix S\n",
    "    of shape NxN where N is number of unique words in corpus including a & b.\n",
    "\n",
    "    Parameters:\n",
    "    a (np.array): bag of words term frequency vector of sentence a\n",
    "    b (np.array): bag of words term frequency vector of sentence b\n",
    "    S (np.array): word similarity matrix\n",
    "\n",
    "    Returns:\n",
    "    float: soft cosine similarity between a & b.\n",
    "   \"\"\"\n",
    "    numerator = a.T@S@b\n",
    "    denominator_a = np.sqrt(a.T@S@a)\n",
    "    denominator_b = np.sqrt(b.T@S@b)\n",
    "    denominator = denominator_a*denominator_b\n",
    "    return round(numerator/denominator,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Matrix Shape: (5, 5)\n"
     ]
    }
   ],
   "source": [
    "sentence_a = ['play','video', 'game'] # unique word representation of sentence a after preprocessing\n",
    "sentence_b = ['best','player'] # unique word representation of sentence b after preprocessing\n",
    "unique_words = ['play','video','game','best','player'] # all unique words in corpus of a & b\n",
    "\n",
    "bow_a = np.array([1, 1, 1, 0, 0], float) # term frequency vector. x[i] = # times unique_words[i] occurs in sentence a.\n",
    "bow_b = np.array([0, 0, 0, 1, 1], float) # term frequency vector. x[i] = # times unique_words[i] occurs in sentence b.\n",
    "\n",
    "# X[i,j] = similarityFunction(unique_words[i], unique_words[j])\n",
    "# similarityFunction can be any function but here its just assumed to be dot product between vector i and vector j.\n",
    "# vector i and vector j are assumed to be loaded from a word-embedding model such as GloVe\n",
    "wordSimilarityMatrix = np.array([[1,0.6,0.65,0.2,0.8],\n",
    "                                 [0.6,1,0.75,0.1,0.6],\n",
    "                                 [0.65,0.75,1,0.2,0.6],\n",
    "                                 [0.2,0.1,0.2,1,0.5],\n",
    "                                 [0.8,0.6,0.5,0.5,1]])\n",
    "\n",
    "print('Similarity Matrix Shape: {}'.format(wordSimilarityMatrix.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.4 µs ± 462 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit softCosineSimilarity(bow_a, bow_b, wordSimilarityMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.4 µs ± 239 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit softCosineSimilarityFast(bow_a, bow_b, wordSimilarityMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosineSimilarity = (bow_a@bow_b)/(np.sqrt(bow_a@bow_a)*np.sqrt(bow_b@bow_b))\n",
    "softCosineSimilarity = softCosineSimilarity(bow_a, bow_b, wordSimilarityMatrix)\n",
    "softCosineSimilarityFast = softCosineSimilarityFast(bow_a, bow_b, wordSimilarityMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.0\n",
      "Soft Cosine Similarity: 0.55\n",
      "Soft Cosine Similarity Fast: 0.55\n"
     ]
    }
   ],
   "source": [
    "print('Cosine Similarity: {}'.format(cosineSimilarity))\n",
    "print('Soft Cosine Similarity: {}'.format(softCosineSimilarity))\n",
    "print('Soft Cosine Similarity Fast: {}'.format(softCosineSimilarityFast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
